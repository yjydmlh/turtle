#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„3å¹´BTC/USDTå†å²Kçº¿æ•°æ®è·å–è„šæœ¬

ä½¿ç”¨é¡¹ç›®ç°æœ‰çš„CRUDç±»å’Œæ•°æ®æ¨¡å‹ï¼Œé«˜æ•ˆè·å–å¹¶æ’å…¥3å¹´å†å²æ•°æ®
"""

import sys
import os
from datetime import datetime, timedelta
import time
from decimal import Decimal

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.db.session import SessionLocal
from app.crud.kline import CRUDKline
from app.schemas.kline import BtcUsdtKlineCreate
from app.core.logger import app_logger
from app.scripts.simple_fetch_data import SimpleBinanceDataFetcher


class OptimizedBtcDataFetcher:
    """ä¼˜åŒ–çš„BTCæ•°æ®è·å–å™¨ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰"""
    
    def __init__(self):
        self.fetcher = SimpleBinanceDataFetcher()
        self.crud = CRUDKline()
        self.symbol = "btc_usdt"
    

    
    def analyze_data_gaps(self):
        """åˆ†ææ•°æ®åº“ä¸­çš„æ•°æ®ç¼ºå£"""
        db = SessionLocal()
        try:
            from app.models.kline import BtcUsdtKline
            from sqlalchemy import func
            
            # æŸ¥è¯¢æ•°æ®åº“ä¸­çš„æ—¶é—´èŒƒå›´
            result = db.query(
                func.min(BtcUsdtKline.timestamp).label('min_timestamp'),
                func.max(BtcUsdtKline.timestamp).label('max_timestamp'),
                func.count(BtcUsdtKline.id).label('total_count')
            ).first()
            
            if not result or not result.min_timestamp:
                app_logger.info("ğŸ“Š æ•°æ®åº“ä¸ºç©ºï¼Œéœ€è¦è·å–å®Œæ•´çš„3å¹´æ•°æ®")
                return self._get_full_range()
            
            # è®¡ç®—3å¹´å‰çš„æ—¶é—´æˆ³
            three_years_ago = datetime.now() - timedelta(days=3*365)
            target_start_timestamp = int(three_years_ago.timestamp() * 1000)
            current_timestamp = int(datetime.now().timestamp() * 1000)
            
            gaps = []
            
            # æ£€æŸ¥å†å²æ•°æ®ç¼ºå£
            if result.min_timestamp > target_start_timestamp:
                gaps.append({
                    'type': 'historical',
                    'start_timestamp': target_start_timestamp,
                    'end_timestamp': result.min_timestamp - 60000,  # å‡1åˆ†é’Ÿé¿å…é‡å¤
                    'description': f'å†å²æ•°æ®ç¼ºå£: {three_years_ago.strftime("%Y-%m-%d")} åˆ° {datetime.fromtimestamp(result.min_timestamp/1000).strftime("%Y-%m-%d")}'
                })
            
            # æ£€æŸ¥æœ€æ–°æ•°æ®ç¼ºå£
            if result.max_timestamp < current_timestamp - 300000:  # 5åˆ†é’Ÿå‰
                gaps.append({
                    'type': 'recent',
                    'start_timestamp': result.max_timestamp + 60000,  # åŠ 1åˆ†é’Ÿé¿å…é‡å¤
                    'end_timestamp': current_timestamp,
                    'description': f'æœ€æ–°æ•°æ®ç¼ºå£: {datetime.fromtimestamp(result.max_timestamp/1000).strftime("%Y-%m-%d")} åˆ°ç°åœ¨'
                })
            
            app_logger.info(f"ğŸ“Š æ•°æ®åº“çŠ¶æ€: å…± {result.total_count} æ¡è®°å½•")
            app_logger.info(f"ğŸ“… æ—¶é—´èŒƒå›´: {datetime.fromtimestamp(result.min_timestamp/1000).strftime('%Y-%m-%d %H:%M')} åˆ° {datetime.fromtimestamp(result.max_timestamp/1000).strftime('%Y-%m-%d %H:%M')}")
            
            if gaps:
                app_logger.info(f"ğŸ” å‘ç° {len(gaps)} ä¸ªæ•°æ®ç¼ºå£:")
                for i, gap in enumerate(gaps, 1):
                    app_logger.info(f"  {i}. {gap['description']}")
            else:
                app_logger.info("âœ… æ•°æ®å®Œæ•´ï¼Œæ— éœ€è¡¥å……")
            
            return gaps
            
        finally:
            db.close()
    
    def _get_full_range(self):
        """è·å–å®Œæ•´çš„3å¹´æ•°æ®èŒƒå›´"""
        three_years_ago = datetime.now() - timedelta(days=3*365)
        current_time = datetime.now()
        
        return [{
            'type': 'full',
            'start_timestamp': int(three_years_ago.timestamp() * 1000),
            'end_timestamp': int(current_time.timestamp() * 1000),
            'description': f'å®Œæ•´3å¹´æ•°æ®: {three_years_ago.strftime("%Y-%m-%d")} åˆ° {current_time.strftime("%Y-%m-%d")}'
        }]
        
    def fetch_specific_range(self, start_date: str, end_date: str, test_mode: bool = False) -> bool:
        """
        è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD
            end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD
            test_mode: æµ‹è¯•æ¨¡å¼ï¼Œåªè·å–å°‘é‡æ•°æ®
        """
        try:
            # è§£ææ—¥æœŸ
            start_dt = datetime.strptime(start_date, "%Y-%m-%d")
            end_dt = datetime.strptime(end_date, "%Y-%m-%d")
            
            app_logger.info(f"ğŸ¯ å¼€å§‹è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„æ•°æ®: {start_date} åˆ° {end_date}")
            
            # æµ‹è¯•è¿æ¥
            if not self.fetcher.test_connection():
                app_logger.error("âŒ å¸å®‰APIè¿æ¥å¤±è´¥")
                return False
            
            # åˆ›å»ºæ—¶é—´èŒƒå›´ç¼ºå£
            gap = {
                'start_timestamp': int(start_dt.timestamp() * 1000),
                'end_timestamp': int(end_dt.timestamp() * 1000),
                'description': f'æŒ‡å®šèŒƒå›´: {start_date} åˆ° {end_date}'
            }
            
            return self._fetch_missing_data([gap], test_mode)
            
        except ValueError as e:
            app_logger.error(f"âŒ æ—¥æœŸæ ¼å¼é”™è¯¯: {str(e)}")
            return False
        except Exception as e:
            app_logger.error(f"âŒ è·å–æŒ‡å®šèŒƒå›´æ•°æ®å¤±è´¥: {str(e)}")
            return False

    def fetch_and_save_3year_data(self, test_mode: bool = False, resume_mode: bool = False):
        """
        è·å–å¹¶ä¿å­˜3å¹´BTC/USDTå†å²æ•°æ®ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
        
        Args:
            test_mode: æµ‹è¯•æ¨¡å¼ï¼Œåªè·å–å°‘é‡æ•°æ®
            resume_mode: æ–­ç‚¹ç»­ä¼ æ¨¡å¼ï¼Œåªè·å–ç¼ºå¤±çš„æ•°æ®
        """
        try:
            app_logger.info("ğŸš€ å¼€å§‹è·å–3å¹´BTC/USDTå†å²Kçº¿æ•°æ®")
            
            # æµ‹è¯•è¿æ¥
            if not self.fetcher.test_connection():
                app_logger.error("âŒ å¸å®‰APIè¿æ¥å¤±è´¥")
                return False
            
            if resume_mode:
                # æ–­ç‚¹ç»­ä¼ æ¨¡å¼ï¼šåˆ†ææ•°æ®ç¼ºå£
                app_logger.info("ğŸ”„ æ–­ç‚¹ç»­ä¼ æ¨¡å¼ï¼šåˆ†ææ•°æ®ç¼ºå£...")
                gaps = self.analyze_data_gaps()
                
                if not gaps:
                    app_logger.info("âœ… æ•°æ®å·²å®Œæ•´ï¼Œæ— éœ€è·å–")
                    return True
                
                return self._fetch_missing_data(gaps, test_mode)
            else:
                # åŸå§‹æ¨¡å¼ï¼šæŒ‰æ—¶é—´é¡ºåºè·å–
                return self._fetch_sequential_data(test_mode)
                
        except Exception as e:
            app_logger.error(f"âŒ è·å–æ•°æ®å¤±è´¥: {str(e)}")
            return False
    
    def _fetch_missing_data(self, gaps: list, test_mode: bool = False) -> bool:
        """è·å–ç¼ºå¤±çš„æ•°æ®"""
        try:
            if test_mode:
                app_logger.info("ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†ç¬¬ä¸€ä¸ªç¼ºå£çš„éƒ¨åˆ†æ•°æ®")
                gaps = gaps[:1]  # åªå¤„ç†ç¬¬ä¸€ä¸ªç¼ºå£
                # é™åˆ¶æµ‹è¯•æ•°æ®é‡
                gap = gaps[0]
                test_end = gap['start_timestamp'] + 3600000  # 1å°æ—¶
                gap['end_timestamp'] = min(gap['end_timestamp'], test_end)
            
            total_saved = 0
            
            for gap_index, gap in enumerate(gaps, 1):
                app_logger.info(f"ğŸ“¦ å¤„ç†ç¼ºå£ {gap_index}/{len(gaps)}: {gap['description']}")
                
                # å°†ç¼ºå£æŒ‰å¤©åˆ†æ‰¹å¤„ç†
                start_timestamp = gap['start_timestamp']
                end_timestamp = gap['end_timestamp']
                
                # æŒ‰7å¤©ä¸ºä¸€æ‰¹å¤„ç†
                batch_size_ms = 7 * 24 * 60 * 60 * 1000  # 7å¤©çš„æ¯«ç§’æ•°
                current_start = start_timestamp
                
                while current_start < end_timestamp:
                    current_end = min(current_start + batch_size_ms, end_timestamp)
                    
                    # è½¬æ¢ä¸ºdatetimeå¯¹è±¡
                    batch_start_time = datetime.fromtimestamp(current_start / 1000)
                    batch_end_time = datetime.fromtimestamp(current_end / 1000)
                    
                    app_logger.info(f"  ğŸ“… å¤„ç†æ—¶é—´æ®µ: {batch_start_time.strftime('%Y-%m-%d %H:%M')} åˆ° {batch_end_time.strftime('%Y-%m-%d %H:%M')}")
                    
                    # è·å–è¿™ä¸€æ‰¹çš„æ•°æ®
                    batch_data = self._fetch_batch_data(batch_start_time, batch_end_time)
                    
                    if batch_data:
                        db = SessionLocal()
                        try:
                            saved_count = self._save_batch_with_crud(db, batch_data)
                            total_saved += saved_count
                            app_logger.info(f"  âœ… æ‰¹æ¬¡å®Œæˆï¼šä¿å­˜ {saved_count} æ¡æ•°æ®")
                        finally:
                            db.close()
                    else:
                        app_logger.warning(f"  âš ï¸ æœªè·å–åˆ°æ•°æ®")
                    
                    current_start = current_end
                    
                    # æ‰¹æ¬¡é—´ä¼‘æ¯
                    if current_start < end_timestamp:
                        app_logger.info("  â³ ä¼‘æ¯2ç§’...")
                        time.sleep(2)
                
                app_logger.info(f"âœ… ç¼ºå£ {gap_index} å®Œæˆ")
                
                # ç¼ºå£é—´ä¼‘æ¯
                if gap_index < len(gaps):
                    app_logger.info("â³ ä¼‘æ¯5ç§’...")
                    time.sleep(5)
            
            app_logger.info(f"ğŸ‰ æ–­ç‚¹ç»­ä¼ å®Œæˆï¼æ€»è®¡ä¿å­˜ {total_saved} æ¡æ•°æ®")
            return total_saved > 0
            
        except Exception as e:
            app_logger.error(f"âŒ æ–­ç‚¹ç»­ä¼ å¤±è´¥: {str(e)}")
            return False
    
    def _fetch_sequential_data(self, test_mode: bool = False) -> bool:
        """æŒ‰æ—¶é—´é¡ºåºè·å–æ•°æ®ï¼ˆåŸå§‹é€»è¾‘ï¼‰"""
        try:
            
            # è®¡ç®—æ—¶é—´èŒƒå›´
            if test_mode:
                # æµ‹è¯•æ¨¡å¼ï¼šåªè·å–æœ€è¿‘1å¤©çš„æ•°æ®
                total_days = 1
                app_logger.info("ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šè·å–æœ€è¿‘1å¤©æ•°æ®")
            else:
                # æ­£å¼æ¨¡å¼ï¼šè·å–3å¹´æ•°æ®
                total_days = 365 * 3
                app_logger.info(f"ğŸ“… æ­£å¼æ¨¡å¼ï¼šè·å–æœ€è¿‘{total_days}å¤©æ•°æ®")
            
            # åˆ†æ‰¹è·å–ï¼Œæ¯æ‰¹7å¤©
            batch_days = 7 if not test_mode else 1
            total_batches = (total_days + batch_days - 1) // batch_days
            
            success_count = 0
            total_saved = 0
            
            app_logger.info(f"ğŸ“¦ å°†åˆ†{total_batches}æ‰¹æ¬¡è·å–ï¼Œæ¯æ‰¹{batch_days}å¤©")
            
            db = SessionLocal()
            try:
                for batch_num in range(total_batches):
                    start_day = batch_num * batch_days
                    end_day = min(start_day + batch_days, total_days)
                    
                    app_logger.info(f"ğŸ“Š æ‰¹æ¬¡ {batch_num + 1}/{total_batches}")
                    
                    # è®¡ç®—è¿™ä¸€æ‰¹çš„æ—¶é—´èŒƒå›´
                    batch_end_time = datetime.now() - timedelta(days=start_day)
                    batch_start_time = batch_end_time - timedelta(days=batch_days)
                    
                    app_logger.info(f"  ğŸ“… æ—¶é—´èŒƒå›´: {batch_start_time.strftime('%Y-%m-%d')} åˆ° {batch_end_time.strftime('%Y-%m-%d')}")
                    
                    # è·å–è¿™ä¸€æ‰¹çš„æ•°æ®
                    batch_data = self._fetch_batch_data(batch_start_time, batch_end_time)
                    
                    if batch_data:
                        # ä½¿ç”¨CRUDç±»ä¿å­˜æ•°æ®
                        saved_count = self._save_batch_with_crud(db, batch_data)
                        total_saved += saved_count
                        success_count += 1
                        
                        app_logger.info(f"  âœ… æ‰¹æ¬¡å®Œæˆï¼šä¿å­˜ {saved_count} æ¡æ•°æ®")
                    else:
                        app_logger.warning(f"  âš ï¸ æ‰¹æ¬¡ {batch_num + 1} æœªè·å–åˆ°æ•°æ®")
                    
                    # æ‰¹æ¬¡é—´ä¼‘æ¯
                    if batch_num < total_batches - 1:
                        app_logger.info("  â³ ä¼‘æ¯2ç§’...")
                        time.sleep(2)
                
                # æœ€ç»ˆç»Ÿè®¡
                success_rate = (success_count / total_batches) * 100
                app_logger.info(f"ğŸ‰ æ•°æ®è·å–å®Œæˆï¼")
                app_logger.info(f"ğŸ“Š æˆåŠŸæ‰¹æ¬¡: {success_count}/{total_batches} ({success_rate:.1f}%)")
                app_logger.info(f"ğŸ’¾ æ€»è®¡ä¿å­˜: {total_saved} æ¡æ•°æ®")
                
                return total_saved > 0
                
            finally:
                db.close()
                
        except Exception as e:
            app_logger.error(f"âŒ è·å–æ•°æ®å¤±è´¥: {str(e)}")
            return False
    
    def _fetch_batch_data(self, start_time: datetime, end_time: datetime) -> list:
        """è·å–ä¸€æ‰¹æ•°æ®"""
        try:
            # ç›´æ¥ä½¿ç”¨æ—¶é—´æˆ³ï¼Œé¿å…æ—¶åŒºè½¬æ¢é—®é¢˜
            since = int(start_time.timestamp() * 1000)
            end_timestamp = int(end_time.timestamp() * 1000)
            
            app_logger.info(f"  ğŸ” è·å–æ—¶é—´èŒƒå›´: {datetime.fromtimestamp(since/1000)} åˆ° {datetime.fromtimestamp(end_timestamp/1000)}")
            
            all_klines = []
            current_since = since
            
            while current_since < end_timestamp:
                try:
                    # è·å–Kçº¿æ•°æ®
                    klines = self.fetcher.exchange.fetch_ohlcv(
                        'BTC/USDT',
                        timeframe='1m',
                        since=current_since,
                        limit=1000
                    )
                    
                    if not klines:
                        app_logger.info(f"  ğŸ“Š æ²¡æœ‰æ›´å¤šæ•°æ®ï¼Œå½“å‰æ—¶é—´æˆ³: {current_since}")
                        break
                    
                    # è¿‡æ»¤æ—¶é—´èŒƒå›´å†…çš„æ•°æ®
                    filtered_klines = [k for k in klines if since <= k[0] < end_timestamp]
                    all_klines.extend(filtered_klines)
                    
                    app_logger.info(f"  ğŸ“ˆ æœ¬æ‰¹è·å– {len(klines)} æ¡ï¼Œè¿‡æ»¤å {len(filtered_klines)} æ¡ï¼Œç´¯è®¡ {len(all_klines)} æ¡")
                    
                    # æ›´æ–°æ—¶é—´æˆ³
                    current_since = klines[-1][0] + 60000  # åŠ 1åˆ†é’Ÿ
                    
                    # å¦‚æœå·²ç»è¶…è¿‡ç»“æŸæ—¶é—´ï¼Œåœæ­¢
                    if current_since >= end_timestamp:
                        break
                    
                    # é¿å…APIé™åˆ¶
                    time.sleep(0.1)
                    
                except Exception as e:
                    app_logger.error(f"  âŒ è·å–æ•°æ®å¤±è´¥: {str(e)}")
                    time.sleep(1)
                    continue
            
            app_logger.info(f"  ğŸ“ˆ è·å–åˆ° {len(all_klines)} æ¡åŸå§‹æ•°æ®")
            return all_klines
            
        except Exception as e:
            app_logger.error(f"âŒ æ‰¹æ¬¡æ•°æ®è·å–å¤±è´¥: {str(e)}")
            return []
    
    def _save_batch_with_crud(self, db, klines_data: list) -> int:
        """ä½¿ç”¨CRUDç±»ä¿å­˜æ‰¹æ¬¡æ•°æ®"""
        saved_count = 0
        skipped_count = 0
        
        app_logger.info(f"  ğŸ’¾ å¼€å§‹ä¿å­˜ {len(klines_data)} æ¡æ•°æ®...")
        
        for kline in klines_data:
            try:
                timestamp = kline[0]
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆé€šè¿‡æ—¶é—´æˆ³æŸ¥è¯¢ï¼‰
                from app.models.kline import BtcUsdtKline
                existing = db.query(BtcUsdtKline).filter(
                    BtcUsdtKline.timestamp == timestamp
                ).first()
                if existing:
                    skipped_count += 1
                    continue
                
                # åˆ›å»ºKçº¿æ•°æ®å¯¹è±¡
                kline_create = BtcUsdtKlineCreate(
                    timestamp=timestamp,
                    open_time=datetime.fromtimestamp(timestamp / 1000),
                    close_time=datetime.fromtimestamp(timestamp / 1000) + timedelta(minutes=1),
                    open_price=Decimal(str(kline[1])),
                    high_price=Decimal(str(kline[2])),
                    low_price=Decimal(str(kline[3])),
                    close_price=Decimal(str(kline[4])),
                    volume=Decimal(str(kline[5])),
                    quote_volume=Decimal(str(kline[5] * kline[4])),
                    trades_count=0,
                    taker_buy_volume=Decimal(str(kline[5] * 0.5)),
                    taker_buy_quote_volume=Decimal(str(kline[5] * kline[4] * 0.5)),
                )
                
                # ä½¿ç”¨CRUDåˆ›å»ºæ•°æ®
                self.crud.create(db, symbol=self.symbol, obj_in=kline_create)
                saved_count += 1
                
            except Exception as e:
                app_logger.error(f"  âŒ ä¿å­˜å•æ¡æ•°æ®å¤±è´¥: {str(e)}")
                continue
        
        app_logger.info(f"  ğŸ“Š ä¿å­˜ç»“æœ: æ–°å¢ {saved_count} æ¡ï¼Œè·³è¿‡ {skipped_count} æ¡")
        return saved_count


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¼˜åŒ–çš„3å¹´BTCæ•°æ®è·å–å™¨ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼ï¼Œåªè·å–å°‘é‡æ•°æ®')
    parser.add_argument('--resume', action='store_true', help='æ–­ç‚¹ç»­ä¼ æ¨¡å¼ï¼Œåªè·å–ç¼ºå¤±çš„æ•°æ®')
    parser.add_argument('--analyze-only', action='store_true', help='ä»…åˆ†ææ•°æ®ç¼ºå£ï¼Œä¸è·å–æ•°æ®')
    parser.add_argument('--fetch-range', nargs=2, metavar=('START_DATE', 'END_DATE'), 
                       help='è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„æ•°æ®ï¼Œæ ¼å¼ï¼šYYYY-MM-DD YYYY-MM-DD')
    
    args = parser.parse_args()
    
    print("=" * 60, flush=True)
    print("ğŸª™ ä¼˜åŒ–çš„BTC/USDT 3å¹´å†å²æ•°æ®è·å–å™¨ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰", flush=True)
    print("=" * 60, flush=True)
    
    start_time = datetime.now()
    print(f"â° å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}", flush=True)
    
    try:
        fetcher = OptimizedBtcDataFetcher()
        
        if args.analyze_only:
            print("\nğŸ” ä»…åˆ†ææ•°æ®ç¼ºå£æ¨¡å¼", flush=True)
            gaps = fetcher.analyze_data_gaps()
            success = True
        elif args.fetch_range:
            print(f"\nğŸ¯ è·å–æŒ‡å®šæ—¶é—´èŒƒå›´æ•°æ®æ¨¡å¼: {args.fetch_range[0]} åˆ° {args.fetch_range[1]}", flush=True)
            success = fetcher.fetch_specific_range(
                start_date=args.fetch_range[0],
                end_date=args.fetch_range[1],
                test_mode=args.test
            )
        else:
            success = fetcher.fetch_and_save_3year_data(
                test_mode=args.test, 
                resume_mode=args.resume
            )
        
        end_time = datetime.now()
        duration = end_time - start_time
        
        print("\n" + "=" * 60, flush=True)
        print(f"â° ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}", flush=True)
        print(f"â±ï¸ æ€»è€—æ—¶: {duration}", flush=True)
        
        if success:
            print("âœ… ä»»åŠ¡å®Œæˆï¼", flush=True)
        else:
            print("âŒ ä»»åŠ¡å¤±è´¥ï¼", flush=True)
        
        print("=" * 60, flush=True)
        
        return 0 if success else 1
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ", flush=True)
        return 1
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}", flush=True)
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)