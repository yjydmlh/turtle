from fastapi import APIRouter, Depends, Query, HTTPException
from sqlalchemy.orm import Session
from typing import Optional

from app.api.deps import get_db
from app.services.kline_aggregator import kline_aggregator
from app.services.chan_adapter import chan_adapter
from app.core.exceptions import create_success_response
from app.core.logger import app_logger

router = APIRouter()


@router.get("/info")
def get_chan_module_info():
    """èŽ·å–Chanæ¨¡å—ä¿¡æ¯å’ŒçŠ¶æ€"""
    try:
        info = chan_adapter.get_chan_info()

        return create_success_response(data={
            "chan_module": info,
            "system_info": {
                "integration_status": "ready" if info["is_available"] else "needs_setup",
                "data_flow": [
                    "1. èŽ·å–Kçº¿æ•°æ® (kline_aggregator)",
                    "2. è°ƒç”¨Chanæ¨¡å—åˆ†æž (chan_adapter)",
                    "3. æ ‡å‡†åŒ–ç»“æžœæ ¼å¼",
                    "4. è¿”å›žç¼ è®ºåˆ†æžç»“æžœ"
                ],
                "supported_analysis": [
                    "åˆ†åž‹è¯†åˆ« (é¡¶åˆ†åž‹ã€åº•åˆ†åž‹)",
                    "ç¬”çš„æž„å»º (ä¸Šæ¶¨ç¬”ã€ä¸‹è·Œç¬”)",
                    "çº¿æ®µåˆ†æž",
                    "ä¹°å–ç‚¹è¯†åˆ«",
                    "è¶‹åŠ¿æ–¹å‘åˆ¤æ–­"
                ]
            }
        })
    except Exception as e:
        app_logger.error(f"âŒ èŽ·å–Chanæ¨¡å—ä¿¡æ¯å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail="èŽ·å–æ¨¡å—ä¿¡æ¯å¤±è´¥")


@router.get("/analyze")
def analyze_chan_theory(
        timeframe: str = Query("1h", description="æ—¶é—´å‘¨æœŸ"),
        limit: int = Query(200, ge=50, le=500, description="åˆ†æžçš„Kçº¿æ•°é‡"),
        db: Session = Depends(get_db)
):
    """
    ç¼ è®ºæŠ€æœ¯åˆ†æž - ä½¿ç”¨é›†æˆçš„Chanæ¨¡å—

    åŠŸèƒ½ç‰¹ç‚¹:
    - è‡ªåŠ¨è¯†åˆ«åˆ†åž‹ï¼ˆé¡¶åˆ†åž‹ðŸ”ºã€åº•åˆ†åž‹ðŸ”»ï¼‰
    - æž„å»ºç¬”çš„ç»“æž„ï¼ˆä¸Šæ¶¨ç¬”ã€ä¸‹è·Œç¬”ï¼‰
    - åˆ†æžçº¿æ®µ
    - è¯†åˆ«ä¹°å–ç‚¹
    - ç”Ÿæˆäº¤æ˜“å»ºè®®

    å‚æ•°:
    - timeframe: æ—¶é—´å‘¨æœŸ (1m, 5m, 15m, 30m, 1h, 4h, 1d)
    - limit: åˆ†æžçš„Kçº¿æ•°é‡ (50-500ï¼Œå»ºè®®200ä»¥ä¸ŠèŽ·å¾—æ›´å¥½æ•ˆæžœ)
    """
    try:
        app_logger.info(f"ðŸ” å¼€å§‹ç¼ è®ºåˆ†æž - å‘¨æœŸ: {timeframe}, æ•°æ®é‡: {limit}")

        # æ£€æŸ¥Chanæ¨¡å—çŠ¶æ€
        if not chan_adapter.is_available:
            app_logger.warning("âš ï¸ Chanæ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–åˆ†æž")

        # èŽ·å–Kçº¿æ•°æ®
        klines = kline_aggregator.aggregate_klines(
            db=db,
            timeframe=timeframe,
            limit=limit
        )

        if not klines:
            raise HTTPException(status_code=404, detail="æ²¡æœ‰æ‰¾åˆ°Kçº¿æ•°æ®ï¼Œè¯·å…ˆè°ƒç”¨ /api/v1/simple/fetch-data èŽ·å–æ•°æ®")

        # ä½¿ç”¨Chanæ¨¡å—è¿›è¡Œåˆ†æž
        analysis_result = chan_adapter.analyze_klines(klines)

        # ç»Ÿè®¡åˆ†æžç»“æžœ
        fenxings_count = len(analysis_result.get('fenxings', []))
        bis_count = len(analysis_result.get('bis', []))
        xianduan_count = len(analysis_result.get('xianduan', []))
        buy_sell_points_count = len(analysis_result.get('buy_sell_points', []))

        if "error" in analysis_result:
            app_logger.warning(f"âš ï¸ åˆ†æžä¸­é‡åˆ°é—®é¢˜: {analysis_result['error']}")

        app_logger.info(
            f"âœ… ç¼ è®ºåˆ†æžå®Œæˆ - åˆ†åž‹: {fenxings_count}, ç¬”: {bis_count}, çº¿æ®µ: {xianduan_count}, ä¹°å–ç‚¹: {buy_sell_points_count}")

        return create_success_response(data={
            "analysis": analysis_result,
            "metadata": {
                "klines_analyzed": len(klines),
                "timeframe": timeframe,
                "analysis_time": klines[-1]["close_time"] if klines else None,
                "latest_price": klines[-1]["close_price"] if klines else None,
                "chan_module_available": chan_adapter.is_available,
                "data_source": analysis_result.get('analysis_summary', {}).get('data_source', 'unknown'),
                "statistics": {
                    "fenxings": fenxings_count,
                    "bis": bis_count,
                    "xianduan": xianduan_count,
                    "buy_sell_points": buy_sell_points_count
                }
            },
            "usage_tips": {
                "fenxings": "ðŸ”ºçº¢è‰²æ ‡è®°ä¸ºé¡¶åˆ†åž‹ï¼ŒðŸ”»ç»¿è‰²æ ‡è®°ä¸ºåº•åˆ†åž‹",
                "bis": "è¿žæŽ¥ç›¸é‚»åˆ†åž‹å½¢æˆçš„ç¬”ï¼Œæ˜¾ç¤ºä»·æ ¼è¿åŠ¨æ–¹å‘",
                "trend": "åŸºäºŽæœ€è¿‘å‡ ç¬”çš„æ–¹å‘å’Œå¼ºåº¦åˆ¤æ–­è¶‹åŠ¿",
                "suggestion": "æ ¹æ®ç¼ è®ºç†è®ºç”Ÿæˆçš„æ“ä½œå»ºè®®ï¼Œä»…ä¾›å‚è€ƒ"
            }
        })

    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"âŒ ç¼ è®ºåˆ†æžå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail="åˆ†æžæœåŠ¡æš‚æ—¶ä¸å¯ç”¨")


@router.get("/chart-data")
def get_chart_data(
        timeframe: str = Query("1h", description="æ—¶é—´å‘¨æœŸ"),
        limit: int = Query(100, ge=20, le=300, description="å›¾è¡¨æ•°æ®é‡"),
        include_analysis: bool = Query(True, description="æ˜¯å¦åŒ…å«åˆ†æžç»“æžœ"),
        db: Session = Depends(get_db)
):
    """
    èŽ·å–å›¾è¡¨æ•°æ® - åŒ…å«Kçº¿å’Œç¼ è®ºåˆ†æžï¼Œé€‚åˆå‰ç«¯å›¾è¡¨æ˜¾ç¤º

    è¿”å›žä¸“é—¨ä¸ºå‰ç«¯å›¾è¡¨ä¼˜åŒ–çš„æ•°æ®æ ¼å¼:
    - æ ‡å‡†çš„Kçº¿æ•°æ®æ ¼å¼ [timestamp, open, high, low, close, volume]
    - ç¼ è®ºåˆ†åž‹æ ‡è®°ç‚¹
    - ç¬”çš„è¿žçº¿æ•°æ®
    - ä¹°å–ç‚¹æ ‡è®°
    """
    try:
        # èŽ·å–Kçº¿æ•°æ®
        klines = kline_aggregator.aggregate_klines(
            db=db,
            timeframe=timeframe,
            limit=limit
        )

        if not klines:
            raise HTTPException(status_code=404, detail="æ²¡æœ‰æ‰¾åˆ°Kçº¿æ•°æ®")

        # å‡†å¤‡å›¾è¡¨æ•°æ®æ ¼å¼ - é€‚é…å‰ç«¯å›¾è¡¨åº“
        chart_data = {
            "klines": [],  # [timestamp, open, high, low, close]
            "volume": [],  # [timestamp, volume]
            "timestamps": []  # æ—¶é—´æ ‡ç­¾æ•°ç»„
        }

        for kline in klines:
            # Kçº¿æ•°æ® - æ ‡å‡†OHLCæ ¼å¼
            chart_data["klines"].append([
                kline["timestamp"],
                float(kline["open_price"]),
                float(kline["high_price"]),
                float(kline["low_price"]),
                float(kline["close_price"])
            ])

            # æˆäº¤é‡æ•°æ®
            chart_data["volume"].append([
                kline["timestamp"],
                float(kline["volume"])
            ])

            # æ—¶é—´æ ‡ç­¾
            chart_data["timestamps"].append(kline["timestamp"])

        result = {
            "chart_data": chart_data,
            "metadata": {
                "timeframe": timeframe,
                "data_count": len(klines),
                "price_range": {
                    "high": max(float(k["high_price"]) for k in klines),
                    "low": min(float(k["low_price"]) for k in klines)
                },
                "time_range": {
                    "start": klines[0]["open_time"],
                    "end": klines[-1]["close_time"]
                }
            }
        }

        # å¦‚æžœéœ€è¦åŒ…å«åˆ†æžç»“æžœ
        if include_analysis and len(klines) >= 20:
            app_logger.info("ðŸ“Š æ‰§è¡Œç¼ è®ºåˆ†æžå¹¶æ·»åŠ å›¾è¡¨æ ‡è®°")

            analysis = chan_adapter.analyze_klines(klines)
            if "error" not in analysis:
                result["analysis"] = analysis

                # ä¸ºå›¾è¡¨å‡†å¤‡åˆ†åž‹æ ‡è®°æ•°æ®
                fenxings_markers = []
                for fx in analysis.get("fenxings", []):
                    fenxings_markers.append({
                        "timestamp": fx["timestamp"],
                        "price": fx["price"],
                        "type": fx["type"],
                        "strength": fx.get("strength", 1.0),
                        "symbol": "ðŸ”º" if fx["type"] == "top" else "ðŸ”»",
                        "color": "#ef4444" if fx["type"] == "top" else "#22c55e"
                    })

                # ä¸ºå›¾è¡¨å‡†å¤‡ç¬”çš„è¿žçº¿æ•°æ®
                bis_lines = []
                for bi in analysis.get("bis", []):
                    if bi.get("start") and bi.get("end"):
                        bis_lines.append({
                            "start": {
                                "timestamp": bi["start"]["timestamp"],
                                "price": bi["start"]["price"]
                            },
                            "end": {
                                "timestamp": bi["end"]["timestamp"],
                                "price": bi["end"]["price"]
                            },
                            "direction": bi["direction"],
                            "color": "#22c55e" if bi["direction"] == "up" else "#ef4444",
                            "width": 2
                        })

                # ä¹°å–ç‚¹æ ‡è®°
                buy_sell_markers = []
                for point in analysis.get("buy_sell_points", []):
                    buy_sell_markers.append({
                        "timestamp": point["timestamp"],
                        "price": point["price"],
                        "type": point["type"],
                        "confidence": point.get("confidence", 0.5),
                        "symbol": "B" if "ä¹°" in point["type"] else "S",
                        "color": "#16a34a" if "ä¹°" in point["type"] else "#dc2626"
                    })

                result["chart_markers"] = {
                    "fenxings": fenxings_markers,
                    "bis_lines": bis_lines,
                    "buy_sell_points": buy_sell_markers
                }

                result["metadata"]["analysis_included"] = True
                result["metadata"]["chan_module_status"] = chan_adapter.is_available

        return create_success_response(data=result)

    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"âŒ èŽ·å–å›¾è¡¨æ•°æ®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail="èŽ·å–å›¾è¡¨æ•°æ®å¤±è´¥")


@router.get("/summary")
def get_analysis_summary(
        timeframe: str = Query("1h", description="æ—¶é—´å‘¨æœŸ"),
        db: Session = Depends(get_db)
):
    """èŽ·å–ç®€åŒ–çš„åˆ†æžæ‘˜è¦ - é€‚åˆå¿«é€ŸæŸ¥çœ‹å¸‚åœºçŠ¶æ€"""
    try:
        # èŽ·å–æœ€è¿‘100æ ¹Kçº¿è¿›è¡Œå¿«é€Ÿåˆ†æž
        klines = kline_aggregator.aggregate_klines(
            db=db,
            timeframe=timeframe,
            limit=100
        )

        if not klines:
            return create_success_response(data={
                "summary": "æš‚æ— æ•°æ®",
                "status": "no_data",
                "recommendation": "è¯·å…ˆè°ƒç”¨ /api/v1/simple/fetch-data èŽ·å–æ•°æ®"
            })

        analysis = chan_adapter.analyze_klines(klines)

        if "error" in analysis:
            return create_success_response(data={
                "summary": f"åˆ†æžå¤±è´¥: {analysis['error']}",
                "status": "error",
                "chan_module_available": chan_adapter.is_available
            })

        summary = analysis.get("analysis_summary", {})
        trend = analysis.get("trend", {})
        latest_price = float(klines[-1]["close_price"])

        # æž„å»ºç®€åŒ–æ‘˜è¦
        quick_summary = {
            "market_status": {
                "current_price": latest_price,
                "trend_direction": trend.get("direction", "neutral"),
                "trend_strength": trend.get("strength", 0),
                "trend_description": {
                    "up": "ðŸ“ˆ ä¸Šæ¶¨è¶‹åŠ¿",
                    "down": "ðŸ“‰ ä¸‹è·Œè¶‹åŠ¿",
                    "neutral": "âž¡ï¸ éœ‡è¡æ•´ç†"
                }.get(trend.get("direction", "neutral"), "âž¡ï¸ éœ‡è¡æ•´ç†")
            },
            "chan_analysis": {
                "fenxings_count": summary.get("total_fenxings", 0),
                "bis_count": summary.get("total_bis", 0),
                "analysis_quality": summary.get("analysis_quality", "unknown"),
                "data_source": summary.get("data_source", "unknown")
            },
            "trading_suggestion": {
                "suggestion": summary.get("suggestion", "ç­‰å¾…æ›´å¤šæ•°æ®"),
                "confidence": "high" if summary.get("analysis_quality") == "good" else "low",
                "risk_level": "medium"  # æ ¹æ®è¶‹åŠ¿å¼ºåº¦å’Œè´¨é‡è®¡ç®—
            },
            "metadata": {
                "timeframe": timeframe,
                "last_update": klines[-1]["close_time"],
                "data_points": len(klines),
                "chan_module_available": chan_adapter.is_available
            }
        }

        # è®¡ç®—é£Žé™©ç­‰çº§
        strength = trend.get("strength", 0)
        quality = summary.get("analysis_quality", "unknown")

        if quality == "good" and strength > 0.7:
            quick_summary["trading_suggestion"]["risk_level"] = "low"
        elif quality == "limited" or strength < 0.3:
            quick_summary["trading_suggestion"]["risk_level"] = "high"

        return create_success_response(data=quick_summary)

    except Exception as e:
        app_logger.error(f"âŒ èŽ·å–åˆ†æžæ‘˜è¦å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail="èŽ·å–æ‘˜è¦å¤±è´¥")


@router.get("/fenxings")
def get_fenxings_only(
        timeframe: str = Query("1h", description="æ—¶é—´å‘¨æœŸ"),
        limit: int = Query(200, ge=50, le=500, description="åˆ†æžçš„Kçº¿æ•°é‡"),
        db: Session = Depends(get_db)
):
    """ä»…èŽ·å–åˆ†åž‹è¯†åˆ«ç»“æžœ - è½»é‡çº§åˆ†æžæŽ¥å£"""
    try:
        klines = kline_aggregator.aggregate_klines(db=db, timeframe=timeframe, limit=limit)

        if not klines:
            raise HTTPException(status_code=404, detail="æ²¡æœ‰æ‰¾åˆ°Kçº¿æ•°æ®")

        analysis = chan_adapter.analyze_klines(klines)
        fenxings = analysis.get("fenxings", [])

        # åˆ†ç±»åˆ†åž‹
        top_fenxings = [fx for fx in fenxings if fx["type"] == "top"]
        bottom_fenxings = [fx for fx in fenxings if fx["type"] == "bottom"]

        return create_success_response(data={
            "fenxings": {
                "all": fenxings,
                "tops": top_fenxings,
                "bottoms": bottom_fenxings
            },
            "statistics": {
                "total": len(fenxings),
                "tops_count": len(top_fenxings),
                "bottoms_count": len(bottom_fenxings),
                "average_strength": sum(fx.get("strength", 0) for fx in fenxings) / len(fenxings) if fenxings else 0
            },
            "metadata": {
                "timeframe": timeframe,
                "klines_analyzed": len(klines),
                "analysis_type": "fenxings_only"
            }
        })

    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"âŒ èŽ·å–åˆ†åž‹æ•°æ®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail="èŽ·å–åˆ†åž‹æ•°æ®å¤±è´¥")


@router.get("/health")
def chan_health_check():
    """ç¼ è®ºåˆ†æžæ¨¡å—å¥åº·æ£€æŸ¥"""
    try:
        chan_info = chan_adapter.get_chan_info()

        health_status = {
            "status": "healthy" if chan_info["is_available"] else "degraded",
            "components": {
                "chan_adapter": "ready",
                "chan_module": "loaded" if chan_info["module_loaded"] else "missing",
                "analysis_capability": "full" if chan_info["is_available"] else "fallback"
            },
            "features": {
                "fenxing_recognition": True,
                "bi_construction": chan_info["is_available"],
                "xianduan_analysis": chan_info["is_available"],
                "buy_sell_points": chan_info["is_available"]
            },
            "performance": {
                "analysis_mode": "chan_module" if chan_info["is_available"] else "fallback",
                "recommended_data_size": "200+ Kçº¿èŽ·å¾—æœ€ä½³æ•ˆæžœ",
                "supported_timeframes": kline_aggregator.get_available_timeframes()
            }
        }

        return create_success_response(data=health_status)

    except Exception as e:
        app_logger.error(f"âŒ ç¼ è®ºæ¨¡å—å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail="å¥åº·æ£€æŸ¥å¤±è´¥")