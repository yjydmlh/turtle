# 性能优化策略

<cite>
**本文档引用的文件**   
- [performance_recommendations.md](file://performance_recommendations.md)
- [database_optimization.sql](file://database_optimization.sql)
- [session.py](file://app/db/session.py)
- [kline_aggregator.py](file://app/services/kline_aggregator.py)
- [kline_simple.py](file://app/api/v1/endpoints/kline_simple.py)
- [config.py](file://app/core/config.py)
</cite>

## 目录
1. [数据库连接池配置](#数据库连接池配置)
2. [大表分区策略](#大表分区策略)
3. [K线数据聚合优化](#k线数据聚合优化)
4. [缓存策略](#缓存策略)
5. [异步处理机制](#异步处理机制)
6. [API限流配置](#api限流配置)
7. [数据压缩与归档](#数据压缩与归档)

## 数据库连接池配置

根据 `app/db/session.py` 文件中的配置，数据库连接池已进行优化，具体参数如下：

- **连接池大小 (pool_size)**: 10  
  初始连接数设置为10，确保系统启动时有足够的连接可用。

- **最大溢出连接数 (max_overflow)**: 20  
  当连接池中的连接全部被占用时，最多可额外创建20个连接，以应对突发的高并发请求。

- **连接回收时间 (pool_recycle)**: 3600秒（1小时）  
  连接在使用1小时后会被回收，防止长时间空闲连接导致的数据库资源浪费或连接失效问题。

- **连接超时 (pool_timeout)**: 30秒  
  当连接池中没有可用连接时，请求最多等待30秒，超时后抛出异常。

- **连接检测 (pool_pre_ping)**: 启用  
  每次从连接池获取连接前，自动检测连接是否有效，避免使用已断开的连接。

这些配置在 `session.py` 中通过 SQLAlchemy 的 `create_engine` 实现，确保了数据库连接的稳定性和高效性。

**Section sources**
- [session.py](file://app/db/session.py#L10-L20)

## 大表分区策略

对于存储大量K线数据的表（如 `btc_usdt`），建议采用按时间分区的策略，以提升查询性能和管理效率。

### 分区SQL示例

```sql
-- 创建2024年BTC/USDT数据分区
CREATE TABLE btc_usdt_2024 PARTITION OF btc_usdt
FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');

-- 创建2025年BTC/USDT数据分区
CREATE TABLE btc_usdt_2025 PARTITION OF btc_usdt
FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');
```

### 索引优化建议

在 `database_optimization.sql` 中提供了关键索引建议，以加速时间范围查询：

```sql
-- 按开盘时间降序索引（常用查询）
CREATE INDEX IF NOT EXISTS idx_btc_usdt_open_time ON btc_usdt(open_time DESC);

-- 时间戳索引（用于精确时间查询）
CREATE INDEX IF NOT EXISTS idx_btc_usdt_timestamp ON btc_usdt(timestamp);

-- 时间范围复合索引
CREATE INDEX IF NOT EXISTS idx_btc_usdt_time_range ON btc_usdt(open_time, close_time);
```

定期执行 `ANALYZE btc_usdt;` 以更新表统计信息，帮助查询优化器生成更优的执行计划。

**Section sources**
- [database_optimization.sql](file://database_optimization.sql#L5-L20)

## K线数据聚合优化

K线数据聚合服务通过 `KlineAggregator` 类实现，位于 `app/services/kline_aggregator.py`，其核心优化策略如下：

### 减少重复计算

- **原始数据源统一**：所有时间周期的K线均基于1分钟原始数据进行聚合，避免多源数据不一致。
- **Pandas高效聚合**：使用 `pandas.resample` 方法对时间序列数据进行聚合，支持开盘价（first）、最高价（max）、最低价（min）、收盘价（last）和成交量（sum）等操作。
- **内存中计算**：数据从数据库加载后在内存中完成聚合，避免多次数据库查询。

### 支持的时间周期

| 时间周期 | 缩写 | 聚合间隔（分钟） |
|--------|------|----------------|
| 1分钟   | 1m   | 1              |
| 5分钟   | 5m   | 5              |
| 15分钟  | 15m  | 15             |
| 30分钟  | 30m  | 30             |
| 1小时   | 1h   | 60             |
| 4小时   | 4h   | 240            |
| 1天    | 1d   | 1440           |

### 查询优化

- **时间范围预计算**：根据请求的 `limit` 和 `timeframe` 自动推算查询时间范围，避免全表扫描。
- **结果截取**：聚合后仅返回指定数量的最新数据，减少网络传输开销。

**Section sources**
- [kline_aggregator.py](file://app/services/kline_aggregator.py#L15-L250)

## 缓存策略

### Redis缓存建议

根据 `performance_recommendations.md` 建议，应引入Redis作为缓存层，缓存热点数据，如：

- 最新K线数据（`/simple/latest` 接口）
- 支持的时间周期列表（`/simple/timeframes`）
- 数据库统计信息（`/simple/stats`）

```python
# 建议安装Redis
pip install redis
```

### 前端缓存实现

前端已实现分层缓存机制，定义在 `frontend/src/lib/api.js`：

- **静态数据**：缓存30分钟（如时间周期描述）
- **历史K线数据**：缓存5分钟
- **实时数据**：缓存30秒

通过 `getCached` 函数实现智能缓存，减少重复请求。

**Section sources**
- [performance_recommendations.md](file://performance_recommendations.md#L35-L40)
- [api.js](file://frontend/src/lib/api.js#L219-L263)

## 异步处理机制

对于耗时操作，如从币安API获取数据，应使用异步处理，避免阻塞主线程。

### 实现方案

在FastAPI中使用 `BackgroundTasks`：

```python
from fastapi import BackgroundTasks

@router.post("/fetch-data")
def fetch_new_data(background_tasks: BackgroundTasks):
    background_tasks.add_task(fetch_from_binance)
    return {"message": "数据获取任务已提交"}
```

当前系统中，`/simple/fetch-data` 接口虽为同步调用，但可通过重构引入 `BackgroundTasks`，提升响应速度。

**Section sources**
- [performance_recommendations.md](file://performance_recommendations.md#L42-L45)
- [kline_simple.py](file://app/api/v1/endpoints/kline_simple.py#L175-L197)

## API限流配置

为防止API被滥用，建议添加限流中间件。

### 配置方法

```python
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.get("/simple/klines")
@limiter.limit("100/minute")
async def get_klines(request: Request):
    pass
```

可针对不同接口设置不同限流策略，例如：

- `/simple/klines`: 100次/分钟
- `/simple/fetch-data`: 10次/小时（防止频繁触发数据抓取）

**Section sources**
- [performance_recommendations.md](file://performance_recommendations.md#L58-L61)

## 数据压缩与归档

### 数据压缩

- 对历史K线数据启用数据库级压缩（如PostgreSQL的TOAST机制）
- 在应用层对返回的JSON数据启用GZIP压缩

### 数据归档策略

1. **按时间归档**：
   - 将超过1年的K线数据迁移到归档表
   - 归档表可使用列式存储格式（如Parquet）以节省空间

2. **定期清理**：
   ```sql
   -- 每月执行一次
   VACUUM ANALYZE btc_usdt;
   ```

3. **冷热数据分离**：
   - 热数据（最近3个月）保留在主数据库
   - 冷数据（3个月前）移至低成本存储

**Section sources**
- [performance_recommendations.md](file://performance_recommendations.md#L63-L66)